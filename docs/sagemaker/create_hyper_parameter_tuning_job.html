<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Starts a hyperparameter tuning job — sagemaker_create_hyper_parameter_tuning_job • paws</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script href="../pkgdown.js"></script>



<meta property="og:title" content="Starts a hyperparameter tuning job — sagemaker_create_hyper_parameter_tuning_job" />

<meta property="og:description" content="Starts a hyperparameter tuning job. A hyperparameter tuning job finds
the best version of a model by running many training jobs on your
dataset using the algorithm you choose and values for hyperparameters
within ranges that you specify. It then chooses the hyperparameter
values that result in a model that performs the best, as measured by an
objective metric that you choose." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="..">paws</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="..">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
</li>
<li>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/paws-r/paws">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Starts a hyperparameter tuning job</h1>
    <small class="dont-index">Source: <a href='https://github.com/paws-r/paws/blob/master/R/sagemaker_operations.R'><code>R/sagemaker_operations.R</code></a></small>
    <div class="hidden name"><code>sagemaker_create_hyper_parameter_tuning_job.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Starts a hyperparameter tuning job. A hyperparameter tuning job finds
the best version of a model by running many training jobs on your
dataset using the algorithm you choose and values for hyperparameters
within ranges that you specify. It then chooses the hyperparameter
values that result in a model that performs the best, as measured by an
objective metric that you choose.</p>
    
    </div>

    <pre class="usage"><span class='fu'>sagemaker_create_hyper_parameter_tuning_job</span>(<span class='no'>HyperParameterTuningJobName</span>,
  <span class='no'>HyperParameterTuningJobConfig</span>, <span class='no'>TrainingJobDefinition</span>, <span class='no'>WarmStartConfig</span>,
  <span class='no'>Tags</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>HyperParameterTuningJobName</th>
      <td><p>[required] The name of the tuning job. This name is the prefix for the names of all
training jobs that this tuning job launches. The name must be unique
within the same AWS account and AWS Region. The name must have   to 
 characters. Valid characters are a-z, A-Z, 0-9, and : + = @ \_ % -
(hyphen). The name is not case sensitive.</p></td>
    </tr>
    <tr>
      <th>HyperParameterTuningJobConfig</th>
      <td><p>[required] The HyperParameterTuningJobConfig object that describes the tuning job,
including the search strategy, the objective metric used to evaluate
training jobs, ranges of parameters to search, and resource limits for
the tuning job. For more information, see automatic-model-tuning</p></td>
    </tr>
    <tr>
      <th>TrainingJobDefinition</th>
      <td><p>The HyperParameterTrainingJobDefinition object that describes the
training jobs that this tuning job launches, including static
hyperparameters, input data configuration, output data configuration,
resource configuration, and stopping condition.</p></td>
    </tr>
    <tr>
      <th>WarmStartConfig</th>
      <td><p>Specifies the configuration for starting the hyperparameter tuning job
using one or more previous tuning jobs as a starting point. The results
of previous tuning jobs are used to inform which combinations of
hyperparameters to search over in the new tuning job.</p>
<p>All training jobs launched by the new hyperparameter tuning job are
evaluated by using the objective metric. If you specify
<code>IDENTICAL_DATA_AND_ALGORITHM</code> as the <code>WarmStartType</code> value for the warm
start configuration, the training job that performs the best in the new
tuning job is compared to the best training jobs from the parent tuning
jobs. From these, the training job that performs the best as measured by
the objective metric is returned as the overall best training job.</p>
<p>All training jobs launched by parent hyperparameter tuning jobs and the
new hyperparameter tuning jobs count against the limit of training jobs
for the tuning job.</p></td>
    </tr>
    <tr>
      <th>Tags</th>
      <td><p>An array of key-value pairs. You can use tags to categorize your AWS
resources in different ways, for example, by purpose, owner, or
environment. For more information, see <a href='https://aws.amazon.com/answers/account-management/aws-tagging-strategies/'>AWS Tagging Strategies</a>.</p>
<p>Tags that you specify for the tuning job are also added to all training
jobs that the tuning job launches.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="request-syntax"><a class="anchor" href="#request-syntax"></a>Request syntax</h2>

    <pre>svc$create_hyper_parameter_tuning_job(
  HyperParameterTuningJobName = "string",
  HyperParameterTuningJobConfig = list(
    Strategy = "Bayesian"|"Random",
    HyperParameterTuningJobObjective = list(
      Type = "Maximize"|"Minimize",
      MetricName = "string"
    ),
    ResourceLimits = list(
      MaxNumberOfTrainingJobs = 123,
      MaxParallelTrainingJobs = 123
    ),
    ParameterRanges = list(
      IntegerParameterRanges = list(
        list(
          Name = "string",
          MinValue = "string",
          MaxValue = "string",
          ScalingType = "Auto"|"Linear"|"Logarithmic"|"ReverseLogarithmic"
        )
      ),
      ContinuousParameterRanges = list(
        list(
          Name = "string",
          MinValue = "string",
          MaxValue = "string",
          ScalingType = "Auto"|"Linear"|"Logarithmic"|"ReverseLogarithmic"
        )
      ),
      CategoricalParameterRanges = list(
        list(
          Name = "string",
          Values = list(
            "string"
          )
        )
      )
    ),
    TrainingJobEarlyStoppingType = "Off"|"Auto"
  ),
  TrainingJobDefinition = list(
    StaticHyperParameters = list(
      "string"
    ),
    AlgorithmSpecification = list(
      TrainingImage = "string",
      TrainingInputMode = "Pipe"|"File",
      AlgorithmName = "string",
      MetricDefinitions = list(
        list(
          Name = "string",
          Regex = "string"
        )
      )
    ),
    RoleArn = "string",
    InputDataConfig = list(
      list(
        ChannelName = "string",
        DataSource = list(
          S3DataSource = list(
            S3DataType = "ManifestFile"|"S3Prefix"|"AugmentedManifestFile",
            S3Uri = "string",
            S3DataDistributionType = "FullyReplicated"|"ShardedByS3Key",
            AttributeNames = list(
              "string"
            )
          )
        ),
        ContentType = "string",
        CompressionType = "None"|"Gzip",
        RecordWrapperType = "None"|"RecordIO",
        InputMode = "Pipe"|"File",
        ShuffleConfig = list(
          Seed = 123
        )
      )
    ),
    VpcConfig = list(
      SecurityGroupIds = list(
        "string"
      ),
      Subnets = list(
        "string"
      )
    ),
    OutputDataConfig = list(
      KmsKeyId = "string",
      S3OutputPath = "string"
    ),
    ResourceConfig = list(
      InstanceType = "ml.m4.xlarge"|"ml.m4.2xlarge"|"ml.m4.4xlarge"|"ml.m4.10xlarge"|"ml.m4.16xlarge"|"ml.m5.large"|"ml.m5.xlarge"|"ml.m5.2xlarge"|"ml.m5.4xlarge"|"ml.m5.12xlarge"|"ml.m5.24xlarge"|"ml.c4.xlarge"|"ml.c4.2xlarge"|"ml.c4.4xlarge"|"ml.c4.8xlarge"|"ml.p2.xlarge"|"ml.p2.8xlarge"|"ml.p2.16xlarge"|"ml.p3.2xlarge"|"ml.p3.8xlarge"|"ml.p3.16xlarge"|"ml.c5.xlarge"|"ml.c5.2xlarge"|"ml.c5.4xlarge"|"ml.c5.9xlarge"|"ml.c5.18xlarge",
      InstanceCount = 123,
      VolumeSizeInGB = 123,
      VolumeKmsKeyId = "string"
    ),
    StoppingCondition = list(
      MaxRuntimeInSeconds = 123
    ),
    EnableNetworkIsolation = TRUE|FALSE,
    EnableInterContainerTrafficEncryption = TRUE|FALSE
  ),
  WarmStartConfig = list(
    ParentHyperParameterTuningJobs = list(
      list(
        HyperParameterTuningJobName = "string"
      )
    ),
    WarmStartType = "IdenticalDataAndAlgorithm"|"TransferLearning"
  ),
  Tags = list(
    list(
      Key = "string",
      Value = "string"
    )
  )
)
</pre>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#request-syntax">Request syntax</a></li>
          </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by David Kretch, Adam Banker.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

